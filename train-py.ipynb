{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport numpy as np\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport os\nfrom torchvision import datasets, models\nfrom collections import OrderedDict\n\ndef get_input_args():\n    parser = argparse.ArgumentParser(description=\"Train a deep learning model on a dataset\")\n    \n    parser.add_argument('data_dir', type=str, help='Path to dataset directory')\n    parser.add_argument('--save_dir', type=str, default='./', help='Directory to save checkpoint')\n    parser.add_argument('--arch', type=str, default='mobilenet_v2', choices=['mobilenet_v2', 'vgg16', 'vgg13'], help='Model architecture')\n    parser.add_argument('--learning_rate', type=float, default=0.001, help='Learning rate for training')\n    parser.add_argument('--hidden_units', type=int, default=512, help='Number of hidden units in classifier')\n    parser.add_argument('--epochs', type=int, default=10, help='Number of epochs for training')\n    parser.add_argument('--gpu', action='store_true', help='Use GPU for training')\n\n    return parser.parse_args()\n\ndef load_data(data_dir):\n    train_dir = os.path.join(data_dir, 'train')\n    valid_dir = os.path.join(data_dir, 'valid')\n    \n    # Define transforms\n    train_transforms = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\n    valid_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n        # Load datasets\n    train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n    valid_dataset = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32)\n\n    return train_loader, valid_loader, train_dataset.class_to_idx\n\ndef build_model(arch, hidden_units):\n    if arch == \"mobilenet_v2\":\n        model = models.mobilenet_v2(pretrained=True)\n        input_size = model.classifier[1].in_features\n    elif arch == \"vgg16\":\n        model = models.vgg16(pretrained=True)\n        input_size = model.classifier[0].in_features\n    elif arch == \"vgg13\":\n        model = models.vgg13(pretrained=True)\n        input_size = model.classifier[0].in_features\n    else:\n        raise ValueError(f\"Unsupported architecture: {arch}\")\n\n    # Freeze pretrained parameters\n    for param in model.parameters():\n        param.requires_grad = False\n\n    # Define a new classifier\n    classifier = nn.Sequential(OrderedDict([\n        ('fc1', nn.Linear(input_size, hidden_units)),\n        ('relu', nn.ReLU()),\n        ('dropout', nn.Dropout(0.2)),\n        ('fc2', nn.Linear(hidden_units, 102)),  # 102 flower categories\n        ('output', nn.LogSoftmax(dim=1))\n    ]))\n    if arch == \"mobilenet_v2\":\n        model.fc = classifier\n    else:\n        model.classifier = classifier\n\n    return model\ndef train_model(model, train_loader, valid_loader, device, epochs, learning_rate):\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\n\n    model.to(device)\n\n    for epoch in range(epochs):\n        train_loss = 0\n        model.train()\n        \n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            output = model(images)\n            loss = criterion(output, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        # Validation step\n        model.eval()\n        valid_loss = 0\n        accuracy = 0\n\n        with torch.no_grad():\n            for images, labels in valid_loader:\n                images, labels = images.to(device), labels.to(device)\n                output = model(images)\n                loss = criterion(output, labels)\n                valid_loss += loss.item()\n\n                # Calculate accuracy\n                probab = torch.softmax(output, dim=1) \n                top_p, top_class = probab.topk(1, dim=1)\n                equals = top_class == labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n\n        print(f\"Epoch {epoch+1}/{epochs}.. \"\n              f\"Train Loss: {train_loss/len(train_loader):.3f}.. \"\n              f\"Validation Loss: {valid_loss/len(valid_loader):.3f}.. \"\n              f\"Validation Accuracy: {accuracy/len(valid_loader)*100:.2f}%\")\n\n    return model, optimizer\ndef save_checkpoint(model, save_dir, arch, class_to_idx):\n    checkpoint = {\n        'arch': arch,\n        'state_dict': model.state_dict(),\n        'classifier': model.classifier,\n        'class_to_idx': class_to_idx\n    }\n    save_path = os.path.join(save_dir, 'checkpoint.pth')\n    torch.save(checkpoint, save_path)\n    print(f\"Checkpoint saved at: {save_path}\")\n\ndef main():\n    args = get_input_args()\n    device = torch.device(\"cuda\" if args.gpu and torch.cuda.is_available() else \"cpu\")\n\n    train_loader, valid_loader, class_to_idx = load_data(args.data_dir)\n    model = build_model(args.arch, args.hidden_units)\n\n    model, optimizer = train_model(model, train_loader, valid_loader, device, args.epochs, args.learning_rate)\n    save_checkpoint(model, args.save_dir, args.arch, class_to_idx)\n\nif __name__ == '__main__':\n    main()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}